Note:

* L'autre useCase : 
  * deux type host et cridentiels 
  * association : en connecte des host, pour acceder au host association cridentiel et host, pour save les cridentiel association host cridentiel. 
  *  

* My usecase : 
  * Five hosts,  Five passwords.
  * We need three type: host, password and user. 
  * Connection between the host.
  * The user store the password. 
  * Host-to-host, host to password.
  * To compromise the host we need to have : 
    * je fish le user, le user me donne le mot de passe avec le mot de passe je m'authentifie et je hack le host.  
  * pour qu'il soit plus competitive : identifie les host non hacker et verifie que le host et connecte avec un host hacker et que on a le mot de passe => hacker le host. 



* sur RDDL: 
  * state-fluent et action fluent diff :
    * State-Fluent: Describes the state or condition of the system. It's about what is.
    * Action-Fluent: Describes the actions or events within the system. It's about what is happening or being done. 
  * carefully consider what information the agent should observe. This will impact how the agent learns and behaves.  


  * peut etre utile : 
    initialTimeToPhish(p1)= 5;
    initialTimeToPhish(p2)= 3;
    initialTimeToPhish(p3)= 3;
    initialTimeToPhish(p4)= 6;
    initialTimeToPhish(p5)= 1;
    initialTimeToPhish(p6)= 8;
    initialTimeToPhish(p7)= 6;
    initialTimeToPhish(p8)= 1;
    initialTimeToPhish(p9)= 5;
    initialTimeToPhish(p10)= 18;


  * question : 
    * comment je peux modeliser un defendeur ? 
    * a quoi sert les observ-fluent, je ne comprend pas ? 
    * mettre en place un algo de RL like q-learning 

* what about the algorithm: 
  * GNN (like GCN, GIN, RGCN, GAT) :    
    * need this two conversion : 
      * vectorized_labels: Converts the state into a tensor of labels, representing the state of attack steps in the simulation.
      * vectorized_log_line: Converts log data into a tensor, representing observed events in the simulation.
  * The inclusion of LSTM layers suggest an application that deals with temporal data or sequential relationships in graphs. 
  * Graph Structure in GNNs:
    * Nodes and Edges: In GNNs, data is represented as a graph, consisting of nodes and edges. Nodes typically represent entities (like hosts, users, or devices in a network), and edges represent relationships or interactions between these entities (like data flows or connections).

    * Features on Nodes and Edges: Each node and edge can have features associated with them. Node features might include properties of the entities (like system characteristics), while edge features could represent characteristics of the interactions (like the type of connection).

Data Generated by the Simulator

The simulation code generates data that mirrors this graph structure:

  * Node Features (graph_index.node_features): The node features are created based on the state of the simulation. For instance, hosts and credentials in the cybersecurity simulation are nodes with specific features indicating their properties or states.

  * Edge Information (graph_index.edge_index, graph_index.edge_type): The simulation defines connections between nodes, represented by edges. The edge_index tensor contains pairs of node indices, indicating which nodes are connected. The edge_type tensor provides information about the type of each connection, which is essential for understanding the nature of interactions in the network.

  * Labels (labels): In supervised learning tasks, each graph (or node) is associated with a label. In this simulation, labels are generated based on the state of attack steps (compromised or not) in the network, which is crucial for tasks like anomaly detection or intrusion prediction.

  * Log Feature Vectors (log_feature_vectors): These represent the log data in vectorized form. In a cybersecurity context, this could include information about events or actions observed in the network over a window of time.

  * Snapshot Data (Data objects): Each snapshot represents the state of the network at a particular timestep. It encapsulates node features, edge information, and labels, forming a complete graph representation suitable for GNNs.

Suitability for GNNs

    Rich Relational Information: GNNs excel at learning from relational data. The structured data from the simulation captures complex relationships and interactions within the network, which is ideal for GNN processing.

    Temporal Dynamics: If the simulation involves changes over time (as indicated by log feature vectors), GNNs, especially those designed to handle temporal data, can learn how the network's state evolves, which is valuable for detecting patterns or predicting future states.

    Feature-Rich Representation: With detailed node and edge features, GNNs can learn nuanced representations of the network, leading to more accurate and insightful models for cybersecurity tasks.